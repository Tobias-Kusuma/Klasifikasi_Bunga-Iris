{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade pip\n",
        "# !pip uninstall numpy\n",
        "# !pip install numpy==1.26.4\n",
        "# !pip uninstall pandas\n",
        "# !pip install pandas==2.1.4\n",
        "# !pip uninstall scikit-learn\n",
        "# !pip install scikit-learn==1.5.1\n",
        "# import sklearn\n",
        "# print(sklearn.__version__)"
      ],
      "metadata": {
        "id": "a0fIoDRzV8Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Penyiapan dan Visualisasi Dataset**"
      ],
      "metadata": {
        "id": "O9jcB671gDwz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b06hKQyMftAX"
      },
      "outputs": [],
      "source": [
        "# import library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "\n",
        "# load dataset\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "# visualisasi dataset\n",
        "import seaborn as sns\n",
        "\n",
        "df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
        "df['Target'] = pd.Series(iris.target)\n",
        "\n",
        "print(\"Data Head: \\n\", df.head(), \"\\n\")\n",
        "print(\"Data Distribution: \\n\", df.describe(), \"\\n\")\n",
        "sns.pairplot(df, hue='Target', palette=(\"tab10\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Splitting, Standarisasi, dan Normalisasi Dataset**"
      ],
      "metadata": {
        "id": "xRBF_4Megkho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting dataset into train-set and test-set\n",
        "from sklearn.model_selection import train_test_split\n",
        "x = iris.data # feature\n",
        "y = iris.target # label (3 kategori: 0, 1, 2)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "\n",
        "print(\"x_train: \", x_train.shape)\n",
        "print(\"y_test: \", y_test.shape)\n",
        "print(\"x_test: \", x_test.shape)\n",
        "print(\"y_train: \", y_train.shape)\n",
        "\n",
        "print(\"Contoh data test: \\n\", x_test)"
      ],
      "metadata": {
        "id": "plXDL2qDg2pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# standarisasi dataset (pemerataan distribusi)\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# scaler = StandardScaler()\n",
        "# scaler.fit(x_train)\n",
        "# x_train = scaler.transform(x_train)\n",
        "# x_test = scaler.transform(x_test)\n",
        "# print(\"data setelah standarisasi: \\n\", x_test)"
      ],
      "metadata": {
        "id": "gQom5k_IhGr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalisasi dataset (mengecilkan/membesarkan jarak antar nilai)\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "normalizer = Normalizer().fit(x_train)\n",
        "x_train = normalizer.transform(x_train)\n",
        "x_test = normalizer.transform(x_test)\n",
        "print(\"data setelah normalisasi: \\n\", x_test)"
      ],
      "metadata": {
        "id": "MkJokoG6hJsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training Model**"
      ],
      "metadata": {
        "id": "jhpFkCRPkmIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# untuned model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "D4P8PuOBhwhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tuned model dengan hyperparameter tuning\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "param_dist = {'n_estimators': randint(50,500), 'max_depth': randint(1,20)}\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "# mencari parameter dengan randomized cv\n",
        "rand_search = RandomizedSearchCV(rf, param_distributions = param_dist, n_iter = 5, cv = 5)\n",
        "\n",
        "rand_search.fit(x_train, y_train)\n",
        "\n",
        "best_rf = rand_search.best_estimator_\n",
        "\n",
        "print('Best hyperparameters:',  rand_search.best_params_)"
      ],
      "metadata": {
        "id": "fmBgxTT4eqb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Uji dan Validasi Hasil**"
      ],
      "metadata": {
        "id": "QHJORCgmld9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# validasi dengan test set\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# # validasi untuk untuned model\n",
        "# y_pred = rf.predict(x_test)\n",
        "\n",
        "# validasi untuk tuned model\n",
        "y_pred = best_rf.predict(x_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Akurasi: \", round(accuracy_score(y_test, y_pred) * 100, 2))\n",
        "print(\"Presisi: \", round(precision_score(y_test, y_pred, average='weighted') * 100, 2))\n",
        "print(\"Recall : \", round(recall_score(y_test, y_pred, average='weighted') * 100, 2))\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "ConfusionMatrixDisplay(cm).plot()"
      ],
      "metadata": {
        "id": "pwx_9YuMliOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validasi dengan k-fold cross-validation\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "\n",
        "# # coba cv untuk untuned model\n",
        "# scores = cross_val_score(rf, x, y, cv=5, scoring='accuracy') * 100\n",
        "\n",
        "# coba cv untuk tuned model\n",
        "scores = cross_val_score(best_rf, x, y, cv=5, scoring='accuracy') * 100\n",
        "\n",
        "print(\"Accuracy per fold: \", scores)\n",
        "print(\"Average accuracy : \", round(scores.mean(), 2), \"%\")"
      ],
      "metadata": {
        "id": "WT_xmIg5c3DQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Visualisasi Hasil**"
      ],
      "metadata": {
        "id": "OFo3vyMIlM1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualisasi random forest\n",
        "from sklearn.tree import export_graphviz\n",
        "from IPython.display import Image\n",
        "import graphviz\n",
        "\n",
        "feature_names = [\"sepal length (cm)\", \"sepal width (cm)\", \"petal length (cm)\", \"petal width (cm)\"]\n",
        "# \"sepal length (cm)\", \"sepal width (cm)\", \"petal length (cm)\", \"petal width (cm)\"\n",
        "\n",
        "# print(\"Jumlah decision tree dalam rf: \", len(rf.estimators_), \"\\n\") # untuned model\n",
        "print(\"Jumlah decision tree dalam rf: \", len(best_rf.estimators_), \"\\n\") # tuned model\n",
        "\n",
        "for i in range(3): # hanya tiga decision tree pertama\n",
        "    # tree = rf.estimators_[i] # untuned model\n",
        "    tree = best_rf.estimators_[i] # tuned model\n",
        "    dot_data = export_graphviz(tree, feature_names = feature_names, filled=True, impurity=False, proportion=True)\n",
        "    graph = graphviz.Source(dot_data)\n",
        "    display(graph)"
      ],
      "metadata": {
        "id": "zvjFfuCYlQip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a series containing feature importances from the model and feature names from the training data\n",
        "# feature_importances = pd.Series(rf.feature_importances_, index=iris.feature_names).sort_values(ascending=False) # untuned model\n",
        "feature_importances = pd.Series(best_rf.feature_importances_, index=iris.feature_names).sort_values(ascending=False) # tuned model\n",
        "\n",
        "# Plot a simple bar chart\n",
        "feature_importances.plot.bar();"
      ],
      "metadata": {
        "id": "cyZGMlr1cg6G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}