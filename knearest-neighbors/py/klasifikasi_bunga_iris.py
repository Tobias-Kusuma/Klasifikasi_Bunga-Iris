# -*- coding: utf-8 -*-
"""Klasifikasi Bunga Iris.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VHCRtgrJEcCzaWljBuiuemfU3BU58GS9

# **Penyiapan Dataset**
"""

# import library
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn
from sklearn import datasets

# load dataset
iris = datasets.load_iris()

# pengecekan dataset
import seaborn as sns

df = pd.DataFrame(iris.data, columns = iris.feature_names)
df['Target'] = pd.Series(iris.target)
print("Data Head: \n", df.head(), "\n")
print("Data Distribution: \n", df.describe(), "\n")
sns.pairplot(df, hue='Target', palette=("tab10"))

"""# **Logistic Regression**"""

# penyiapan dataset
import sklearn
from sklearn import datasets
from sklearn.model_selection import train_test_split

iris = datasets.load_iris()
x = iris.data
y = iris.target

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)

print("x_train: ", x_train.shape)
print("x_test: ", x_test.shape)
print("y_train: ", y_train.shape)
print("y_test: ", y_test.shape)



"""# **Decision Trees**"""

# penyiapan dataset

import sklearn
from sklearn import datasets
from sklearn.model_selection import train_test_split

iris = datasets.load_iris()
x = iris.data
y = iris.target

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)

print("x_train: ", x_train.shape)
print("x_test: ", x_test.shape)
print("y_train: ", y_train.shape)
print("y_test: ", y_test.shape)

"""# **Random Forest**"""

# penyiapan dataset

import sklearn
from sklearn import datasets
from sklearn.model_selection import train_test_split

iris = datasets.load_iris()
x = iris.data
y = iris.target

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)

print("x_train: ", x_train.shape)
print("x_test: ", x_test.shape)
print("y_train: ", y_train.shape)
print("y_test: ", y_test.shape)

"""# **KNN**"""

# splitting dataset into train-set and test-set
from sklearn.model_selection import train_test_split
x = iris.data # feature
y = iris.target # label
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)

print("x_train: ", x_train.shape)
print("y_test: ", y_test.shape)
print("x_test: ", x_test.shape)
print("y_train: ", y_train.shape)

# standarisasi dataset (perataan distribusi)
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(x_train)

x_train = scaler.transform(x_train)
x_test = scaler.transform(x_test)

# pengecekan konstanta k-fold
from sklearn import neighbors

error = []
for i in range(1, 40):
    knn = neighbors.KNeighborsClassifier(n_neighbors = i)
    knn.fit(x_train, y_train)

    prediction_i = knn.predict(x_test)
    error.append(np.mean(prediction_i != y_test))

plt.figure()
plt.plot(range(1, 40), error, color='red', marker='.',
         markerfacecolor='blue', markersize=10)
plt.title('Rata-Rata Error terhadap nilai K')
plt.xlabel('Nilai K')
plt.ylabel('Rata-Rata Error')
plt.show()

# training model dan evaluasi
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay

knn = neighbors.KNeighborsClassifier(n_neighbors = 11)
knn.fit(x_train, y_train)
y_pred = knn.predict(x_test)

print(classification_report(y_test, y_pred))
print("Akurasi: ", round(accuracy_score(y_test, y_pred) * 100, 2), "%\n")

cm = confusion_matrix(y_test, y_pred)
ConfusionMatrixDisplay(cm).plot()

"""# **SVM**"""

# penyiapan dataset

import sklearn
from sklearn import datasets
from sklearn.model_selection import train_test_split

iris = datasets.load_iris()
x = iris.data
y = iris.target

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)

print("x_train: ", x_train.shape)
print("x_test: ", x_test.shape)
print("y_train: ", y_train.shape)
print("y_test: ", y_test.shape)

"""# **Naive-Bayes**"""

# penyiapan dataset

import sklearn
from sklearn import datasets
from sklearn.model_selection import train_test_split

iris = datasets.load_iris()
x = iris.data
y = iris.target

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)

print("x_train: ", x_train.shape)
print("x_test: ", x_test.shape)
print("y_train: ", y_train.shape)
print("y_test: ", y_test.shape)