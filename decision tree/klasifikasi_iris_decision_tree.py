# -*- coding: utf-8 -*-
"""Klasifikasi Iris - Decision Tree.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NimOUiJyG4eoM_QT9_uEVS0bvbzTFyuu
"""

# !pip install --upgrade pip
# !pip install --upgrade numpy
# !pip install --upgrade pandas
# !pip install --upgrade scikit-learn
# import sklearn
# print(sklearn.__version__)

"""## **Persiapan dan Visualisasi Dataset**"""

# import library
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn
from sklearn import datasets

# load dataset
iris = datasets.load_iris()

# visualisasi dataset
import seaborn as sns

df = pd.DataFrame(iris.data, columns = iris.feature_names)
df['Target'] = pd.Series(iris.target)

print("Data Head: \n", df.head(), "\n")
print("Data Distribution: \n", df.describe(), "\n")
sns.pairplot(df, hue='Target', palette=("tab10"))

"""## **Splitting, Standarisasi, dan Normalisasi Dataset**"""

# splitting dataset into train-set and test-set
from sklearn.model_selection import train_test_split
x = iris.data # feature
y = iris.target # label (3 kategori: 0, 1, 2)
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)

print("x_train: ", x_train.shape)
print("y_test: ", y_test.shape)
print("x_test: ", x_test.shape)
print("y_train: ", y_train.shape)

print("\nContoh data testing: \n", x_test)

# standarisasi dataset (distribusi diratakan menjadi sekitar 0 dan ada negatifnya)
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(x_train)
x_train = scaler.transform(x_train)
x_test = scaler.transform(x_test)

print("Data setelah standarisasi: \n", x_test)

# normalisasi dataset (menormalisasi skala menjadi -1x1)
from sklearn.preprocessing import Normalizer

normalizer = Normalizer().fit(x_train)
x_train = normalizer.transform(x_train)
x_test = normalizer.transform(x_test)

print("Data setelah normalisasi: \n", x_test)

"""## **Training Model**"""

# untuned model
from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier()
dt.fit(x_train, y_train)

# tuned model
from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier(criterion='entropy', max_depth=30, min_samples_split=3)
dt.fit(x_train, y_train)

"""## **Validasi Model**"""

from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

y_pred = dt.predict(x_test)

print(classification_report(y_test, y_pred))
print("Akurasi: ", round(accuracy_score(y_test, y_pred) * 100, 2))
print("Presisi: ", round(precision_score(y_test, y_pred, average='weighted') * 100, 2))
print("Recall : ", round(recall_score(y_test, y_pred, average='weighted') * 100, 2), "\n")

cm = confusion_matrix(y_test, y_pred)
ConfusionMatrixDisplay(cm).plot()

"""## **Visualisasi Hasil**"""

from sklearn.tree import export_graphviz
from io import StringIO ## for Python 3
from IPython.display import Image
import pydotplus

dot_data = StringIO()
export_graphviz(dt, out_file = dot_data, filled = True, rounded = True, special_characters = True,
    feature_names = iris.feature_names, class_names=['0','1', '2'])
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
graph.write_png('iris.png')
Image(graph.create_png())

# Create a series containing feature importances from the model and feature names from the training data
feature_importances = pd.Series(dt.feature_importances_, index=iris.feature_names).sort_values(ascending=False)

# Plot a simple bar chart
feature_importances.plot.bar();